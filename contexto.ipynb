{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593dba10",
   "metadata": {},
   "source": [
    "## Explicaci√≥n de los modelos balanceados\n",
    "\n",
    "En los siguientes bloques se presentan cinco modelos de clasificaci√≥n (Regresi√≥n Log√≠stica, KNN, Naive Bayes, LDA y QDA) aplicados sobre datos balanceados. El balanceo se realiza √∫nicamente sobre el conjunto de entrenamiento, utilizando la t√©cnica de sobremuestreo (RandomOverSampler), para corregir el desbalance de clases en la variable respuesta.\n",
    "\n",
    "**¬øPor qu√© balancear?**\n",
    "\n",
    "En problemas de clasificaci√≥n con clases desbalanceadas, los modelos tienden a favorecer la clase mayoritaria, lo que puede ocultar un mal desempe√±o en las clases minoritarias. Balancear el conjunto de entrenamiento permite que el modelo aprenda de manera m√°s equitativa sobre todas las clases, mejorando la capacidad de predecir correctamente las clases menos representadas.\n",
    "\n",
    "**¬øC√≥mo se implementa el balanceo aqu√≠?**\n",
    "\n",
    "1. Primero, se divide el dataset en entrenamiento (80%) y prueba (20%) usando `train_test_split`.\n",
    "2. Solo el 80% de entrenamiento se balancea con RandomOverSampler, generando copias sint√©ticas de las clases minoritarias hasta igualar la cantidad de muestras de la clase mayoritaria.\n",
    "3. El 20% de prueba se mantiene intacto y representa la distribuci√≥n real de los datos, permitiendo evaluar el desempe√±o del modelo en un escenario realista.\n",
    "4. Se entrena cada modelo sobre el set balanceado y se eval√∫a sobre el set de prueba original.\n",
    "\n",
    "**Ventajas de este enfoque:**\n",
    "- Permite comparar el desempe√±o de los modelos con y sin balanceo.\n",
    "- Mejora la sensibilidad y el recall en las clases minoritarias.\n",
    "- La m√©trica de exactitud (accuracy) en test sigue siendo representativa, ya que el test no est√° balanceado artificialmente.\n",
    "\n",
    "**Modelos balanceados incluidos:**\n",
    "- Regresi√≥n Log√≠stica Multinomial (balanceada)\n",
    "- KNN (balanceado)\n",
    "- Naive Bayes (balanceado)\n",
    "- LDA (balanceado)\n",
    "- QDA (balanceado)\n",
    "\n",
    "Cada bloque de c√≥digo correspondiente incluye una nota aclaratoria sobre el procedimiento de balanceo y la divisi√≥n 80/20.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e0d9a",
   "metadata": {},
   "source": [
    "### Informe individual: Regresi√≥n Log√≠stica Multinomial (balanceada)\n",
    "\n",
    "La regresi√≥n log√≠stica multinomial balanceada permite modelar la probabilidad de pertenencia a cada clase de calidad de vino, considerando todas las clases simult√°neamente. Al balancear el set de entrenamiento, el modelo aprende de manera equitativa sobre todas las calidades, evitando el sesgo hacia la clase mayoritaria. \n",
    "\n",
    "- **Exactitud en test:** Indica el porcentaje de vinos correctamente clasificados sobre el conjunto de prueba real (no balanceado artificialmente).\n",
    "- **Reporte de clasificaci√≥n:** Muestra precisi√≥n, recall y F1-score para cada clase, permitiendo analizar el desempe√±o en clases minoritarias.\n",
    "- **Validaci√≥n cruzada:** El accuracy promedio en 5 folds sobre el set balanceado da una idea de la robustez del modelo.\n",
    "- **Matriz de confusi√≥n:** Permite visualizar los aciertos y errores de predicci√≥n para cada clase.\n",
    "\n",
    "Este modelo es √∫til cuando se busca una clasificaci√≥n general robusta y se quiere evitar el sesgo hacia la clase m√°s frecuente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8059da",
   "metadata": {},
   "source": [
    "### Informe individual: KNN (balanceado)\n",
    "\n",
    "El modelo KNN (K-Nearest Neighbors) balanceado clasifica cada vino seg√∫n la mayor√≠a de sus vecinos m√°s cercanos en el espacio de caracter√≠sticas, considerando la misma cantidad de ejemplos de cada clase gracias al balanceo.\n",
    "\n",
    "- **Exactitud en test:** Refleja la proporci√≥n de vinos correctamente clasificados en el conjunto de prueba real.\n",
    "- **Reporte de clasificaci√≥n:** Permite analizar el comportamiento del modelo en cada clase, especialmente en las menos representadas.\n",
    "- **Validaci√≥n cruzada:** El accuracy promedio en 5 folds sobre el set balanceado muestra la estabilidad del modelo ante diferentes particiones.\n",
    "- **Matriz de confusi√≥n:** Visualiza los aciertos y errores de predicci√≥n por clase.\n",
    "\n",
    "KNN balanceado es √∫til cuando se espera que la proximidad en el espacio de variables sea relevante para la clasificaci√≥n y se quiere evitar el sesgo hacia la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b29ac7",
   "metadata": {},
   "source": [
    "### Informe individual: Naive Bayes (balanceado)\n",
    "\n",
    "El modelo Naive Bayes balanceado asume independencia entre las variables predictoras y utiliza la probabilidad condicional para clasificar cada vino. El balanceo del set de entrenamiento permite que el modelo aprenda de manera justa sobre todas las clases, mejorando la predicci√≥n de las menos frecuentes.\n",
    "\n",
    "- **Exactitud en test:** Mide el porcentaje de vinos correctamente clasificados en el conjunto de prueba real.\n",
    "- **Reporte de clasificaci√≥n:** Permite evaluar precisi√≥n, recall y F1-score para cada clase, mostrando el desempe√±o en clases minoritarias.\n",
    "- **Validaci√≥n cruzada:** El accuracy promedio en 5 folds sobre el set balanceado indica la robustez del modelo.\n",
    "- **Matriz de confusi√≥n:** Muestra los aciertos y errores de predicci√≥n por clase.\n",
    "\n",
    "Naive Bayes balanceado es especialmente √∫til cuando se busca un modelo simple, r√°pido y que no requiera muchas suposiciones sobre la relaci√≥n entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c8f48",
   "metadata": {},
   "source": [
    "### Informe individual: LDA (balanceado)\n",
    "\n",
    "El modelo LDA (An√°lisis Discriminante Lineal) balanceado busca encontrar combinaciones lineales de las variables predictoras que mejor separen las clases de calidad de vino. El balanceo del set de entrenamiento permite que el modelo aprenda fronteras de decisi√≥n m√°s justas para todas las clases.\n",
    "\n",
    "- **Exactitud en test:** Indica la proporci√≥n de vinos correctamente clasificados en el conjunto de prueba real.\n",
    "- **Reporte de clasificaci√≥n:** Permite analizar el desempe√±o en cada clase, especialmente en las menos representadas.\n",
    "- **Validaci√≥n cruzada:** El accuracy promedio en 5 folds sobre el set balanceado muestra la estabilidad del modelo.\n",
    "- **Matriz de confusi√≥n:** Visualiza los aciertos y errores de predicci√≥n por clase.\n",
    "\n",
    "LDA balanceado es √∫til cuando se espera que las clases sean separables linealmente y se busca mejorar la predicci√≥n en clases minoritarias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da500c6",
   "metadata": {},
   "source": [
    "### Informe individual: QDA (balanceado)\n",
    "\n",
    "El modelo QDA (An√°lisis Discriminante Cuadr√°tico) balanceado permite que las fronteras de decisi√≥n entre clases sean curvas, adapt√°ndose mejor a relaciones no lineales entre las variables y la calidad del vino. El balanceo del set de entrenamiento asegura que el modelo aprenda de manera justa sobre todas las clases.\n",
    "\n",
    "- **Exactitud en test:** Refleja el porcentaje de vinos correctamente clasificados en el conjunto de prueba real.\n",
    "- **Reporte de clasificaci√≥n:** Permite analizar precisi√≥n, recall y F1-score para cada clase, mostrando el desempe√±o en clases minoritarias.\n",
    "- **Validaci√≥n cruzada:** El accuracy promedio en 5 folds sobre el set balanceado indica la robustez del modelo.\n",
    "- **Matriz de confusi√≥n:** Visualiza los aciertos y errores de predicci√≥n por clase.\n",
    "\n",
    "QDA balanceado es especialmente √∫til cuando se sospecha que las clases no son separables linealmente y se busca mejorar la predicci√≥n en clases menos frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c21705",
   "metadata": {},
   "source": [
    "## Comparaci√≥n de modelos balanceados y elecci√≥n del mejor\n",
    "\n",
    "A continuaci√≥n se comparan los cinco modelos de clasificaci√≥n balanceados aplicados al dataset de calidad de vinos:\n",
    "\n",
    "**1. Regresi√≥n Log√≠stica Multinomial (balanceada):**\n",
    "- Suele ofrecer buen desempe√±o general y m√©tricas equilibradas en todas las clases.\n",
    "- Es robusta y f√°cil de interpretar, pero puede verse limitada si las relaciones entre variables y clases no son lineales.\n",
    "\n",
    "**2. KNN (balanceado):**\n",
    "- Su desempe√±o depende mucho de la elecci√≥n de k y de la escala de los datos.\n",
    "- Puede captar relaciones no lineales, pero es sensible al ruido y a la cantidad de datos.\n",
    "\n",
    "**3. Naive Bayes (balanceado):**\n",
    "- Es muy r√°pido y simple, pero su supuesto de independencia entre variables rara vez se cumple en la pr√°ctica.\n",
    "- Puede funcionar bien si las variables son poco correlacionadas.\n",
    "\n",
    "**4. LDA (balanceado):**\n",
    "- Busca separar las clases mediante combinaciones lineales de variables.\n",
    "- Es efectivo si las clases son separables linealmente y las covarianzas son similares.\n",
    "\n",
    "**5. QDA (balanceado):**\n",
    "- Permite fronteras de decisi√≥n curvas, adapt√°ndose mejor a relaciones complejas.\n",
    "- Puede sobreajustar si hay pocas muestras por clase, pero es potente si hay suficiente informaci√≥n.\n",
    "\n",
    "### ¬øC√≥mo elegir el mejor modelo?\n",
    "\n",
    "Para elegir el mejor modelo, se deben comparar principalmente:\n",
    "- **Exactitud en test:** Qu√© porcentaje de vinos clasifica correctamente el modelo sobre datos reales.\n",
    "- **Recall y F1-score en clases minoritarias:** Indican la capacidad de detectar correctamente las clases menos frecuentes.\n",
    "- **Robustez (validaci√≥n cruzada):** Qu√© tan estable es el modelo ante diferentes particiones de los datos.\n",
    "\n",
    "### Recomendaci√≥n final\n",
    "\n",
    "En la mayor√≠a de los casos pr√°cticos con este tipo de datos, **la Regresi√≥n Log√≠stica Multinomial balanceada** suele ser la mejor opci√≥n por su equilibrio entre interpretabilidad, robustez y buen desempe√±o en todas las clases, especialmente cuando el dataset no es muy grande y las relaciones no son extremadamente complejas. Adem√°s, su exactitud y m√©tricas suelen ser competitivas o superiores a las alternativas, y es menos propensa al sobreajuste que QDA.\n",
    "\n",
    "**Por lo tanto, para tu TP, recomiendo utilizar la Regresi√≥n Log√≠stica Multinomial balanceada como modelo principal de clasificaci√≥n.**\n",
    "\n",
    "No obstante, si observas que QDA o KNN logran m√©tricas significativamente mejores en recall/F1 para las clases minoritarias (y no hay sobreajuste), podr√≠as considerarlos como alternativas. Pero en general, la regresi√≥n log√≠stica balanceada es la opci√≥n m√°s s√≥lida y defendible para tu informe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7091b48",
   "metadata": {},
   "source": [
    "# üìò Informe T√©cnico: Comparaci√≥n de Modelos de Clasificaci√≥n Multiclase Balanceados\n",
    "\n",
    "## üß™ Contexto del Estudio\n",
    "\n",
    "Este an√°lisis se realiz√≥ sobre el dataset `winequality-red.csv`, que contiene caracter√≠sticas fisicoqu√≠micas de vinos tintos y su calidad (variable multiclase). El objetivo fue comparar cinco modelos de clasificaci√≥n bajo condiciones controladas:\n",
    "\n",
    "- Divisi√≥n 80/20 con `stratify=y`\n",
    "- Balanceo con `RandomOverSampler` aplicado solo al conjunto de entrenamiento\n",
    "- Escalado con `StandardScaler`\n",
    "- Evaluaci√≥n sobre el conjunto de test original (sin balancear)\n",
    "- M√©tricas utilizadas: Accuracy, Precision, Recall, F1-score (macro) + Validaci√≥n cruzada (CV)\n",
    "\n",
    "## üß† Modelos evaluados\n",
    "\n",
    "- Regresi√≥n Log√≠stica (multinomial)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Naive Bayes (GaussianNB)\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Crear tabla desde metricas_modelos\n",
    "tabla_test = pd.DataFrame.from_dict(metricas_modelos, orient='index')\n",
    "tabla_test.index.name = \"Modelo\"\n",
    "tabla_test = tabla_test.reset_index()\n",
    "\n",
    "# Ordenar por F1 Score\n",
    "tabla_test_ordenada = tabla_test.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "tabla_test_ordenada\n",
    "\n",
    "# Asegurarse de tener estas variables definidas previamente\n",
    "cv_scores = {\n",
    "    \"Regresi√≥n Log√≠stica\": scores_log_bal,\n",
    "    \"KNN\": scores_knn_bal,\n",
    "    \"Naive Bayes\": scores_nb_bal,\n",
    "    \"LDA\": scores_lda_bal,\n",
    "    \"QDA\": scores_qda_bal\n",
    "}\n",
    "\n",
    "# Crear tabla de CV Accuracy\n",
    "tabla_cv = pd.DataFrame({\n",
    "    \"Modelo\": list(cv_scores.keys()),\n",
    "    \"CV Accuracy (media)\": [cv_scores[m].mean() for m in cv_scores]\n",
    "})\n",
    "\n",
    "# Ordenar por rendimiento\n",
    "tabla_cv.sort_values(by=\"CV Accuracy (media)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "## üìà An√°lisis gr√°fico\n",
    "\n",
    "### 1. Boxplot de Accuracy (Validaci√≥n Cruzada)\n",
    "- KNN: caja estrecha, sin outliers ‚Üí comportamiento confiable\n",
    "- QDA: buena mediana, pero m√°s dispersi√≥n\n",
    "- Log√≠stica y Naive Bayes: baja mediana, mayor ruido\n",
    "- LDA: intermedio\n",
    "\n",
    "### 2. Gr√°fico de Barras (M√©tricas en Test)\n",
    "- QDA tiene las barras m√°s altas en todas las m√©tricas\n",
    "- KNN lo sigue de cerca, especialmente en Accuracy y F1\n",
    "- Naive Bayes queda rezagado en todas las m√©tricas\n",
    "\n",
    "## ‚úÖ Conclusi√≥n\n",
    "\n",
    "**üèÜ Mejor modelo: QDA (Quadratic Discriminant Analysis)**  \n",
    "- Mejor rendimiento en test (todas las m√©tricas)\n",
    "- Mayor capacidad de generalizaci√≥n multiclase\n",
    "- Buen balance entre precisi√≥n y cobertura\n",
    "\n",
    "**ü•à Segundo lugar: KNN**  \n",
    "- Excelente estabilidad en validaci√≥n cruzada\n",
    "- Buen rendimiento general, aunque con menor Recall\n",
    "\n",
    "## üìå Recomendaciones\n",
    "\n",
    "- Explorar ajustes de hiperpar√°metros en QDA y KNN\n",
    "- Evaluar curvas ROC por clase para an√°lisis m√°s fino\n",
    "- Probar modelos ensemble (Random Forest, AdaBoost) como siguiente paso"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
