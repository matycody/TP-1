{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593dba10",
   "metadata": {},
   "source": [
    "## Explicación de los modelos balanceados\n",
    "\n",
    "En los siguientes bloques se presentan cinco modelos de clasificación (Regresión Logística, KNN, Naive Bayes, LDA y QDA) aplicados sobre datos balanceados. El balanceo se realiza únicamente sobre el conjunto de entrenamiento, utilizando la técnica de sobremuestreo (RandomOverSampler), para corregir el desbalance de clases en la variable respuesta.\n",
    "\n",
    "**¿Por qué balancear?**\n",
    "\n",
    "En problemas de clasificación con clases desbalanceadas, los modelos tienden a favorecer la clase mayoritaria, lo que puede ocultar un mal desempeño en las clases minoritarias. Balancear el conjunto de entrenamiento permite que el modelo aprenda de manera más equitativa sobre todas las clases, mejorando la capacidad de predecir correctamente las clases menos representadas.\n",
    "\n",
    "**¿Cómo se implementa el balanceo aquí?**\n",
    "\n",
    "1. Primero, se divide el dataset en entrenamiento (80%) y prueba (20%) usando `train_test_split`.\n",
    "2. Solo el 80% de entrenamiento se balancea con RandomOverSampler, generando copias sintéticas de las clases minoritarias hasta igualar la cantidad de muestras de la clase mayoritaria.\n",
    "3. El 20% de prueba se mantiene intacto y representa la distribución real de los datos, permitiendo evaluar el desempeño del modelo en un escenario realista.\n",
    "4. Se entrena cada modelo sobre el set balanceado y se evalúa sobre el set de prueba original.\n",
    "\n",
    "**Ventajas de este enfoque:**\n",
    "- Permite comparar el desempeño de los modelos con y sin balanceo.\n",
    "- Mejora la sensibilidad y el recall en las clases minoritarias.\n",
    "- La métrica de exactitud (accuracy) en test sigue siendo representativa, ya que el test no está balanceado artificialmente.\n",
    "\n",
    "**Modelos balanceados incluidos:**\n",
    "- Regresión Logística Multinomial (balanceada)\n",
    "- KNN (balanceado)\n",
    "- Naive Bayes (balanceado)\n",
    "- LDA (balanceado)\n",
    "- QDA (balanceado)\n",
    "\n",
    "Cada bloque de código correspondiente incluye una nota aclaratoria sobre el procedimiento de balanceo y la división 80/20.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e0d9a",
   "metadata": {},
   "source": [
    "### Informe individual: Regresión Logística Multinomial (balanceada)\n",
    "\n",
    "La regresión logística multinomial balanceada permite modelar la probabilidad de pertenencia a cada clase de calidad de vino, considerando todas las clases simultáneamente. Al balancear el set de entrenamiento, el modelo aprende de manera equitativa sobre todas las calidades, evitando el sesgo hacia la clase mayoritaria. \n",
    "\n",
    "- **Exactitud en test:** Indica el porcentaje de vinos correctamente clasificados sobre el conjunto de prueba real (no balanceado artificialmente).\n",
    "- **Reporte de clasificación:** Muestra precisión, recall y F1-score para cada clase, permitiendo analizar el desempeño en clases minoritarias.\n",
    "- **Validación cruzada:** El accuracy promedio en 5 folds sobre el set balanceado da una idea de la robustez del modelo.\n",
    "- **Matriz de confusión:** Permite visualizar los aciertos y errores de predicción para cada clase.\n",
    "\n",
    "Este modelo es útil cuando se busca una clasificación general robusta y se quiere evitar el sesgo hacia la clase más frecuente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8059da",
   "metadata": {},
   "source": [
    "### Informe individual: KNN (balanceado)\n",
    "\n",
    "El modelo KNN (K-Nearest Neighbors) balanceado clasifica cada vino según la mayoría de sus vecinos más cercanos en el espacio de características, considerando la misma cantidad de ejemplos de cada clase gracias al balanceo.\n",
    "\n",
    "- **Exactitud en test:** Refleja la proporción de vinos correctamente clasificados en el conjunto de prueba real.\n",
    "- **Reporte de clasificación:** Permite analizar el comportamiento del modelo en cada clase, especialmente en las menos representadas.\n",
    "- **Validación cruzada:** El accuracy promedio en 5 folds sobre el set balanceado muestra la estabilidad del modelo ante diferentes particiones.\n",
    "- **Matriz de confusión:** Visualiza los aciertos y errores de predicción por clase.\n",
    "\n",
    "KNN balanceado es útil cuando se espera que la proximidad en el espacio de variables sea relevante para la clasificación y se quiere evitar el sesgo hacia la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b29ac7",
   "metadata": {},
   "source": [
    "### Informe individual: Naive Bayes (balanceado)\n",
    "\n",
    "El modelo Naive Bayes balanceado asume independencia entre las variables predictoras y utiliza la probabilidad condicional para clasificar cada vino. El balanceo del set de entrenamiento permite que el modelo aprenda de manera justa sobre todas las clases, mejorando la predicción de las menos frecuentes.\n",
    "\n",
    "- **Exactitud en test:** Mide el porcentaje de vinos correctamente clasificados en el conjunto de prueba real.\n",
    "- **Reporte de clasificación:** Permite evaluar precisión, recall y F1-score para cada clase, mostrando el desempeño en clases minoritarias.\n",
    "- **Validación cruzada:** El accuracy promedio en 5 folds sobre el set balanceado indica la robustez del modelo.\n",
    "- **Matriz de confusión:** Muestra los aciertos y errores de predicción por clase.\n",
    "\n",
    "Naive Bayes balanceado es especialmente útil cuando se busca un modelo simple, rápido y que no requiera muchas suposiciones sobre la relación entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c8f48",
   "metadata": {},
   "source": [
    "### Informe individual: LDA (balanceado)\n",
    "\n",
    "El modelo LDA (Análisis Discriminante Lineal) balanceado busca encontrar combinaciones lineales de las variables predictoras que mejor separen las clases de calidad de vino. El balanceo del set de entrenamiento permite que el modelo aprenda fronteras de decisión más justas para todas las clases.\n",
    "\n",
    "- **Exactitud en test:** Indica la proporción de vinos correctamente clasificados en el conjunto de prueba real.\n",
    "- **Reporte de clasificación:** Permite analizar el desempeño en cada clase, especialmente en las menos representadas.\n",
    "- **Validación cruzada:** El accuracy promedio en 5 folds sobre el set balanceado muestra la estabilidad del modelo.\n",
    "- **Matriz de confusión:** Visualiza los aciertos y errores de predicción por clase.\n",
    "\n",
    "LDA balanceado es útil cuando se espera que las clases sean separables linealmente y se busca mejorar la predicción en clases minoritarias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da500c6",
   "metadata": {},
   "source": [
    "### Informe individual: QDA (balanceado)\n",
    "\n",
    "El modelo QDA (Análisis Discriminante Cuadrático) balanceado permite que las fronteras de decisión entre clases sean curvas, adaptándose mejor a relaciones no lineales entre las variables y la calidad del vino. El balanceo del set de entrenamiento asegura que el modelo aprenda de manera justa sobre todas las clases.\n",
    "\n",
    "- **Exactitud en test:** Refleja el porcentaje de vinos correctamente clasificados en el conjunto de prueba real.\n",
    "- **Reporte de clasificación:** Permite analizar precisión, recall y F1-score para cada clase, mostrando el desempeño en clases minoritarias.\n",
    "- **Validación cruzada:** El accuracy promedio en 5 folds sobre el set balanceado indica la robustez del modelo.\n",
    "- **Matriz de confusión:** Visualiza los aciertos y errores de predicción por clase.\n",
    "\n",
    "QDA balanceado es especialmente útil cuando se sospecha que las clases no son separables linealmente y se busca mejorar la predicción en clases menos frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c21705",
   "metadata": {},
   "source": [
    "## Comparación de modelos balanceados y elección del mejor\n",
    "\n",
    "A continuación se comparan los cinco modelos de clasificación balanceados aplicados al dataset de calidad de vinos:\n",
    "\n",
    "**1. Regresión Logística Multinomial (balanceada):**\n",
    "- Suele ofrecer buen desempeño general y métricas equilibradas en todas las clases.\n",
    "- Es robusta y fácil de interpretar, pero puede verse limitada si las relaciones entre variables y clases no son lineales.\n",
    "\n",
    "**2. KNN (balanceado):**\n",
    "- Su desempeño depende mucho de la elección de k y de la escala de los datos.\n",
    "- Puede captar relaciones no lineales, pero es sensible al ruido y a la cantidad de datos.\n",
    "\n",
    "**3. Naive Bayes (balanceado):**\n",
    "- Es muy rápido y simple, pero su supuesto de independencia entre variables rara vez se cumple en la práctica.\n",
    "- Puede funcionar bien si las variables son poco correlacionadas.\n",
    "\n",
    "**4. LDA (balanceado):**\n",
    "- Busca separar las clases mediante combinaciones lineales de variables.\n",
    "- Es efectivo si las clases son separables linealmente y las covarianzas son similares.\n",
    "\n",
    "**5. QDA (balanceado):**\n",
    "- Permite fronteras de decisión curvas, adaptándose mejor a relaciones complejas.\n",
    "- Puede sobreajustar si hay pocas muestras por clase, pero es potente si hay suficiente información.\n",
    "\n",
    "### ¿Cómo elegir el mejor modelo?\n",
    "\n",
    "Para elegir el mejor modelo, se deben comparar principalmente:\n",
    "- **Exactitud en test:** Qué porcentaje de vinos clasifica correctamente el modelo sobre datos reales.\n",
    "- **Recall y F1-score en clases minoritarias:** Indican la capacidad de detectar correctamente las clases menos frecuentes.\n",
    "- **Robustez (validación cruzada):** Qué tan estable es el modelo ante diferentes particiones de los datos.\n",
    "\n",
    "### Recomendación final\n",
    "\n",
    "En la mayoría de los casos prácticos con este tipo de datos, **la Regresión Logística Multinomial balanceada** suele ser la mejor opción por su equilibrio entre interpretabilidad, robustez y buen desempeño en todas las clases, especialmente cuando el dataset no es muy grande y las relaciones no son extremadamente complejas. Además, su exactitud y métricas suelen ser competitivas o superiores a las alternativas, y es menos propensa al sobreajuste que QDA.\n",
    "\n",
    "**Por lo tanto, para tu TP, recomiendo utilizar la Regresión Logística Multinomial balanceada como modelo principal de clasificación.**\n",
    "\n",
    "No obstante, si observas que QDA o KNN logran métricas significativamente mejores en recall/F1 para las clases minoritarias (y no hay sobreajuste), podrías considerarlos como alternativas. Pero en general, la regresión logística balanceada es la opción más sólida y defendible para tu informe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7091b48",
   "metadata": {},
   "source": [
    "# 📘 Informe Técnico: Comparación de Modelos de Clasificación Multiclase Balanceados\n",
    "\n",
    "## 🧪 Contexto del Estudio\n",
    "\n",
    "Este análisis se realizó sobre el dataset `winequality-red.csv`, que contiene características fisicoquímicas de vinos tintos y su calidad (variable multiclase). El objetivo fue comparar cinco modelos de clasificación bajo condiciones controladas:\n",
    "\n",
    "- División 80/20 con `stratify=y`\n",
    "- Balanceo con `RandomOverSampler` aplicado solo al conjunto de entrenamiento\n",
    "- Escalado con `StandardScaler`\n",
    "- Evaluación sobre el conjunto de test original (sin balancear)\n",
    "- Métricas utilizadas: Accuracy, Precision, Recall, F1-score (macro) + Validación cruzada (CV)\n",
    "\n",
    "## 🧠 Modelos evaluados\n",
    "\n",
    "- Regresión Logística (multinomial)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Naive Bayes (GaussianNB)\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Crear tabla desde metricas_modelos\n",
    "tabla_test = pd.DataFrame.from_dict(metricas_modelos, orient='index')\n",
    "tabla_test.index.name = \"Modelo\"\n",
    "tabla_test = tabla_test.reset_index()\n",
    "\n",
    "# Ordenar por F1 Score\n",
    "tabla_test_ordenada = tabla_test.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "tabla_test_ordenada\n",
    "\n",
    "# Asegurarse de tener estas variables definidas previamente\n",
    "cv_scores = {\n",
    "    \"Regresión Logística\": scores_log_bal,\n",
    "    \"KNN\": scores_knn_bal,\n",
    "    \"Naive Bayes\": scores_nb_bal,\n",
    "    \"LDA\": scores_lda_bal,\n",
    "    \"QDA\": scores_qda_bal\n",
    "}\n",
    "\n",
    "# Crear tabla de CV Accuracy\n",
    "tabla_cv = pd.DataFrame({\n",
    "    \"Modelo\": list(cv_scores.keys()),\n",
    "    \"CV Accuracy (media)\": [cv_scores[m].mean() for m in cv_scores]\n",
    "})\n",
    "\n",
    "# Ordenar por rendimiento\n",
    "tabla_cv.sort_values(by=\"CV Accuracy (media)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "## 📈 Análisis gráfico\n",
    "\n",
    "### 1. Boxplot de Accuracy (Validación Cruzada)\n",
    "- KNN: caja estrecha, sin outliers → comportamiento confiable\n",
    "- QDA: buena mediana, pero más dispersión\n",
    "- Logística y Naive Bayes: baja mediana, mayor ruido\n",
    "- LDA: intermedio\n",
    "\n",
    "### 2. Gráfico de Barras (Métricas en Test)\n",
    "- QDA tiene las barras más altas en todas las métricas\n",
    "- KNN lo sigue de cerca, especialmente en Accuracy y F1\n",
    "- Naive Bayes queda rezagado en todas las métricas\n",
    "\n",
    "## ✅ Conclusión\n",
    "\n",
    "**🏆 Mejor modelo: QDA (Quadratic Discriminant Analysis)**  \n",
    "- Mejor rendimiento en test (todas las métricas)\n",
    "- Mayor capacidad de generalización multiclase\n",
    "- Buen balance entre precisión y cobertura\n",
    "\n",
    "**🥈 Segundo lugar: KNN**  \n",
    "- Excelente estabilidad en validación cruzada\n",
    "- Buen rendimiento general, aunque con menor Recall\n",
    "\n",
    "## 📌 Recomendaciones\n",
    "\n",
    "- Explorar ajustes de hiperparámetros en QDA y KNN\n",
    "- Evaluar curvas ROC por clase para análisis más fino\n",
    "- Probar modelos ensemble (Random Forest, AdaBoost) como siguiente paso"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
