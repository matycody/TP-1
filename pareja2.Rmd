---
title: "TP1 - Inferencia Estadística y Reconocimiento de Patrones"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(tidyverse)
library(corrplot)
library(glmnet)
library(GGally)
knitr::opts_chunk$set(echo = TRUE)
```

# Parte de regresión en R

## Carga de datos y exploración

```{r}
# Borrar variables previas	rm(list = ls())
# Cargar el dataset
vinos <- read.csv2("winequality-red.csv", dec = ".")
# Nombres y estructura
names(vinos)
head(vinos)
summary(vinos)
```

## Estadísticas descriptivas y correlaciones

```{r}
# Matriz de correlación y dispersión
ggcorr(vinos, label = TRUE)
corrplot(cor(vinos), method = 'color', tl.cex = 0.7)
ggpairs(vinos, columns = 1:12, title = "Matriz de correlaciones y dispersión")
cor(vinos$quality, vinos[, 1:12])
```

## División en train/test

```{r}
set.seed(1)
train_idx <- sample(seq_len(nrow(vinos)), size = 0.8 * nrow(vinos))
train <- vinos[train_idx, ]
test <- vinos[-train_idx, ]
X_train <- as.matrix(train[, !(names(train) %in% c('quality'))])
y_train <- train$quality
X_test <- as.matrix(test[, !(names(test) %in% c('quality'))])
y_test <- test$quality
```

# Modelos de regresión

## Regresión lineal múltiple

```{r}
lm_fit <- lm(quality ~ ., data = train)
summary(lm_fit)
lm_pred <- predict(lm_fit, newdata = test)
cat('Regresión lineal múltiple:\n')
cat('Error Cuadrático Medio (MSE):', mean((test$quality - lm_pred)^2), '\n')
cat('R2:', summary(lm_fit)$r.squared, '\n')
```

### Gráficos de residuos (lineal)

```{r}
residuos <- resid(lm_fit)
ajustados <- fitted(lm_fit)
hist(residuos, breaks = 30, col = "steelblue", main = "Distribución de residuos", xlab = "Residuos")
plot(ajustados, residuos, xlab = "Valores ajustados", ylab = "Residuos", main = "Residuos vs Valores ajustados", pch = 20, col = "darkred")
abline(h = 0, lty = 2, col = "gray")
```

## Ridge

```{r}
cv_ridge <- cv.glmnet(X_train, y_train, alpha = 0)
best_lambda_ridge <- cv_ridge$lambda.min
ridge_pred <- predict(cv_ridge, s = best_lambda_ridge, newx = X_test)
r2_ridge <- 1 - sum((y_test - ridge_pred)^2) / sum((y_test - mean(y_test))^2)
cat('\nRidge:\n')
cat("Error Cuadrático Medio (MSE): ", mean((y_test - ridge_pred)^2), '\n')
cat('R2:', r2_ridge, '\n')
```

### Gráficos de residuos (Ridge)

```{r}
residuos_ridge <- y_test-ridge_pred
hist(residuos_ridge, breaks = 30, col = "tomato", main = "Residuos del modelo penalizado", xlab = "Residuos")
plot(ridge_pred, residuos_ridge, xlab = "Valores ajustados", ylab = "Residuos", main = "Residuos vs Valores ajustados (penalizado)", pch = 20, col = "blue")
abline(h = 0, lty = 2, col = "gray")
```

## LASSO

```{r}
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1)
best_lambda_lasso <- cv_lasso$lambda.min
lasso_pred <- predict(cv_lasso, s = best_lambda_lasso, newx = X_test)
r2_lasso <- 1 - sum((y_test - lasso_pred)^2) / sum((y_test - mean(y_test))^2)
cat('\nLASSO:\n')
cat("Error Cuadrático Medio (MSE): ", mean((y_test - lasso_pred)^2), '\n')
cat('R2:', r2_lasso, '\n')
```

### Gráficos de residuos (LASSO)

```{r}
residuos_lasso <- y_test-lasso_pred
hist(residuos_lasso, breaks = 30, col = "tomato", main = "Residuos del modelo penalizado", xlab = "Residuos")
plot(lasso_pred, residuos_lasso, xlab = "Valores ajustados", ylab = "Residuos", main = "Residuos vs Valores ajustados (penalizado)", pch = 20, col = "blue")
abline(h = 0, lty = 2, col = "gray")
```
